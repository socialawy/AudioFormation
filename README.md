
# ğŸ­ AudioFormation

## Description

**Production audio pipeline: Voice, SFX, Music, Mix, Export.**

Companion to VideoFormation (same architecture, different domain).

### Philosophy (Mirrors VideoFormation)

Principle	| Implementation
-----------|---------------
Single Source of Truth	| project.json governs everything
Validation Gates	| Hard gates before generation, mixing, export
Automation First	| CLI drives pipeline; dashboard is optional
Engine Agnostic	| Swap TTS/music engines without touching project files
Hardware Aware	| Auto-detects GPU, suggests optimal engine
Bilingual First	| Arabic + English as primary languages

## Quick Start

```bash
# Install
pip install -e ".[dev,server]"

pip install "audioformation[server]"

# Create a project
audioformation new "MY_NOVEL"

# Start the Dashboard
audioformation serve
# Open http://localhost:4001 in your browser
```

Or use the CLI:

```bash
# Ingest text
audioformation ingest MY_NOVEL --source ./chapters/

# Generate (edge-tts with gTTS fallback)
audioformation generate MY_NOVEL --engine edge

# Mix (Voice + Music + Ducking)
audioformation mix MY_NOVEL

# Export
audioformation export MY_NOVEL --format m4b
```

## Requirements
Python 3.11+
ffmpeg on PATH
Optional: NVIDIA GPU with 4GB+ VRAM for XTTS voice cloning

## Features
Feature | Status
-------|-------
Edge TTS (free, Arabic + English) | âœ… BUILT
SSML direction mapping | âœ… BUILT
Text chunking (breath-group) | âœ… BUILT
Per-chapter QC scanning | âœ… BUILT
QC Scan API endpoint | âœ… BUILT
LUFS normalization | âœ… BUILT
MP3 export with manifest | âœ… BUILT
Arabic diacritics detection | âœ… BUILT
Engine fallback chain (edge-tts â†’ gTTS) | âœ… BUILT
XTTS v2 engine adapter | âœ… BUILT
ElevenLabs engine adapter | âœ… BUILT
Multi-speaker dialogue | âœ… BUILT
Ambient pad generation | âœ… BUILT
VAD-based ducking | âœ… BUILT
M4B audiobook export | âœ… BUILT
Web dashboard | âœ… BUILT
Run All Pipeline | âœ… BUILT

## Architecture

AudioFormation follows a modular pipeline architecture with five core domains:

```
audioformation CLI â†’ Pipeline State Machine
â”œâ”€â”€ TTS Engines (edge, gtts, xtts, elevenlabs) âœ… IMPLEMENTED
â”œâ”€â”€ Audio Processor (normalize, trim, stitch) âœ… IMPLEMENTED  
â”œâ”€â”€ Ambient Composer (pad generation) âœ… IMPLEMENTED
â”œâ”€â”€ Mixer (multi-track, VAD ducking) âœ… IMPLEMENTED
â”œâ”€â”€ QC Scanner (per-chunk quality) âœ… IMPLEMENTED
â””â”€â”€ Exporter (MP3/M4B + manifest) âœ… IMPLEMENTED
```

### Implementation Status

- âœ… **Phase 1 Complete**: Core TTS pipeline, QC, audio processing
- âœ… **Phase 2 Complete**: Cloud TTS adapters, voice cloning, multi-speaker, CLI tools
- âœ… **Phase 3 Complete**: Mixer with ducking, M4B export, web interface (Editor/Mix)
- â³ **Phase 4 Future**: Algorithmic composition, advanced features

## Dashboard

The dashboard (`audioformation serve`) provides a visual interface for:
*   **Project Management**: Create and list projects.
*   **Editor**: Configure generation settings, edit chapter metadata, trigger generation per-chapter.
*   **Mix & Review**: Visualize audio waveforms (`wavesurfer.js`), play back generated/mixed audio, trigger the mixing pipeline.
*   **Run All Pipeline**: Single-click execution of entire audiobook workflow (validate â†’ generate â†’ QC scan â†’ process â†’ compose â†’ mix â†’ export).

## Testing
```bash
pip install -e ".[dev]"
pytest -v
# or
pytest --cov=src --cov-report=term-missing
```

## Contributing
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License
MIT
