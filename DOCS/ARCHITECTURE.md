
# ğŸ­ AudioFormation â€” Planning/ARCHITECTURE Document


## Production audio pipeline: Voice, SFX, Music, Mix, Export.

Companion to VideoFormation (same architecture, different domain). 

### Philosophy (Mirrors VideoFormation)

Principle	| Implementation
-----------|---------------
Single Source of Truth	| project.json governs everything
Validation Gates	| Hard gates before generation, mixing, export
Automation First	| CLI drives pipeline; dashboard is a bonus
Engine Agnostic	| Swap TTS/music engines without touching project files
Hardware Aware	| Auto-detects GPU, suggests optimal engine
Bilingual First	| Arabic + English as primary languages

### Architecture
```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 audioformation CLI                  â”‚
â”‚         python -m audioformation <command>          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   FastAPI Server                    â”‚
â”‚               localhost:4001/api/*                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Vox  â”‚ FX   â”‚Comp  â”‚ Mix  â”‚ Ship                    â”‚
â”‚Engineâ”‚Forge â”‚Engineâ”‚ Bus  â”‚ (Export)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Project Manager                        â”‚
â”‚        (JSON-driven, file-system backed)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚            Web Dashboard (localhost:4001)           â”‚
â”‚     Projects â”‚ Editor â”‚ Timeline â”‚ Mix â”‚ Export     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
### Five Engines
1. VoxEngine (Voice/Narration)
```text
Providers (priority order):
â”œâ”€â”€ edge-tts # âœ… BUILT: Free, fast, excellent Arabic
â”‚ â”œâ”€â”€ Voices: ar-SA-HamedNeural, ar-EG, ar-AE-FatimaNeural, etc.
â”‚ â”œâ”€â”€ Full list: edge-tts --list-voices | grep ar-
â”‚ â”œâ”€â”€ âœ… BUILT: Tested with Arabic content
â”‚ â”œâ”€â”€ âš ï¸ PATCHED: Upgraded to v7 to resolve 403 DRM token errors
â”‚ â””â”€â”€ Risk: unofficial MS wrapper, no SLA, IP throttle at heavy scale
â”‚
â”œâ”€â”€ gtts # âœ… BUILT: Emergency fallback engine
â”‚ â”œâ”€â”€ Google Translate TTS, free tier
â”‚ â”œâ”€â”€ Activated on edge-tts 403/500 errors
â”‚ â”œâ”€â”€ Quality: Acceptable for emergencies, not primary
â”‚ â””â”€â”€ No API key required, rate-limited
â”‚
â”œâ”€â”€ coqui-tts (XTTS-v2) # âœ… BUILT: Local voice cloning
â”‚ â”œâ”€â”€ Install: pip install coqui-tts (Idiap community fork)
â”‚ â”œâ”€â”€ 17 languages including Arabic
â”‚ â”œâ”€â”€ 6-second voice clone from reference audio
â”‚ â”œâ”€â”€ âœ… GPU validated: 1.5GB headroom on 4GB GTX 1650 Ti
â”‚ â”œâ”€â”€ âœ… Performance: 3.8s per 200-char chunk
â”‚ â”œâ”€â”€ âš ï¸ CRITICAL: Long-form narration requires aggressive chunking
â”‚ â”‚ â”œâ”€â”€ Split text into breath-groups (2-3 sentences, max ~200 chars)
â”‚ â”‚ â”œâ”€â”€ Generate each chunk with SAME reference audio
â”‚ â”‚ â”œâ”€â”€ Crossfade chunks (50ms overlap)
â”‚ â”‚ â”œâ”€â”€ Fixed generation params across all chunks for consistency
â”‚ â”‚ â””â”€â”€ Auto-retry failed chunks (max 3 attempts)
â”‚ â””â”€â”€ Pin version in pyproject.toml â€” community-maintained
â”‚
â”œâ”€â”€ elevenlabs # âœ… BUILT: Premium cloud fallback
â”‚ â””â”€â”€ Best overall quality, strong Arabic, free tier, pay-per-use, voice cloning support
â”‚
â”œâ”€â”€ openai-tts # Priority 4: If Arabic quality improves (Phase 5)
â”‚
â””â”€â”€ gemini-tts # Priority 5: If rate limits ease (Phase 5)

#### Built Engines Summary (Phase 1â€“2)

| Engine | Type | Status | Notes |
|:---|:---|:---|:---|
| **Edge-TTS** | Cloud | âœ… Phase 1 | Streaming synthesis, ~100ms latency, free tier |
| **gTTS** | Cloud | âœ… Phase 1 | Fallback engine, slow but reliable, no API key |
| **XTTS v2.0** | Local | âœ… Phase 2 | Speaker cloning, async generation, 30â€“60s per 10min |
| **ElevenLabs** | Cloud | âœ… Phase 2 | Voice ID mapping, pooled HTTP client, awaits API key |

Features:
â”œâ”€â”€ Character profiles (voice + persona + direction per character)
â”œâ”€â”€ Voice cloning workflow (reference audio â†’ XTTS)
â”œâ”€â”€ Chapter-aware chunking (auto-split long text at sentence boundaries)
â”œâ”€â”€ Arabic diacritics preprocessing
â”œâ”€â”€ Sentence-level retry on generation failure
â”œâ”€â”€ âœ… BUILT: Engine fallback chain: edge-tts â†’ gTTS â†’ cloud engines
â”œâ”€â”€ âœ… BUILT: Automatic retry with fallback on 403/500 errors
â”œâ”€â”€ âœ… BUILT: Per-chunk QC scan (SNR, pitch continuity, duration sanity)
â””â”€â”€ âœ… BUILT: Engine availability detection and graceful degradation

#### Engine Fallback Chain (âœ… BUILT)

AudioFormation implements automatic engine fallback to ensure robust generation:

```text
Primary: edge-tts (v7+)
â”‚ â”œâ”€â”€ Fast, high-quality Arabic voices
â”‚ â”œâ”€â”€ Free, no API key required
â”‚ â””â”€â”€ âš ï¸ PATCHED: v7 resolves 403 DRM token errors
â”‚
Fallback 1: gTTS (âœ… BUILT)
â”‚ â”œâ”€â”€ Activated on edge-tts failures (403, 500, timeout)
â”‚ â”œâ”€â”€ Google Translate TTS, free tier
â”‚ â”œâ”€â”€ Quality: Acceptable for emergencies
â”‚ â””â”€â”€ Automatic retry with gTTS on edge-tts errors
â”‚
Fallback 2: Cloud engines (âœ… BUILT)
â”‚ â”œâ”€â”€ ElevenLabs (Adapter ready), OpenAI TTS, Gemini TTS (Phase 3)
â”‚ â”œâ”€â”€ Pay-per-use, premium quality
â”‚ â””â”€â”€ Configurable API keys in 00_CONFIG/engines.json
```

Implementation:
- src/audioformation/engines/registry.py: Engine priority and fallback logic
- src/audioformation/engines/gtts_engine.py: gTTS implementation
- src/audioformation/engines/elevenlabs.py: ElevenLabs cloud adapter (ready for API key)
- Automatic retry with next engine on generation failure
- User-configurable engine preferences per character

#### Test Infrastructure & Coverage

**371 tests (100% passing), all isolated and mocked:**

| Characteristic | Status | Notes |
|:---|:---|:---|
| Real API calls (edge-tts, gTTS, ElevenLabs) | âŒ None | All tests use MagicMock/AsyncMock |
| Network dependency | âŒ None | CI/CD fully deterministic |
| Test runtime | âœ… 10.7s | Fast, parallelizable suite |
| Isolation strategy | âœ… Complete | `conftest.py` monkeypatches PROJECTS_ROOT to tmp_path |
| Coverage by area | âœ… Comprehensive | Text handling, chunking, engines (abstract), multi-speaker, export, validation, QC |
| Real-world API validation | âš ï¸ Manual only | Tested outside automated suite (documented in BUILD_LOG) |

**Test mocking approach:**
- Engine tests: Use `MagicMock` for TTS library (torch, coqui-tts) and `AsyncMock` for async generation
- Project tests: Redirect `PROJECTS_ROOT` to isolated `tmp_path`  
- External services: Mock httpx for ElevenLabs, mock edge-tts responses
- No environment variables required (API keys auto-mocked)

- SSML Direction Mapping (edge-tts)

The `direction` field in chapter schema maps to SSML parameters,
giving edge-tts actual voice control beyond plain text.
```text
Direction Field â†’ SSML Mapping:

pace:
â”œâ”€â”€ "very slow" â†’ <prosody rate="slowest">
â”œâ”€â”€ "slow" â†’ <prosody rate="slow">
â”œâ”€â”€ "moderate" â†’ (no tag)
â”œâ”€â”€ "fast" â†’ <prosody rate="fast">
â””â”€â”€ "very fast" â†’ <prosody rate="fastest">

energy:
â”œâ”€â”€ "whisper" â†’ <prosody volume="x-soft">
â”œâ”€â”€ "quiet" â†’ <prosody volume="soft">
â”œâ”€â”€ "normal" â†’ (no tag)
â”œâ”€â”€ "loud" â†’ <prosody volume="loud">
â””â”€â”€ "intense" â†’ <prosody volume="x-loud">

emotion:
â”œâ”€â”€ Mapped to emphasis + pitch combinations
â”œâ”€â”€ "wonder" â†’ <emphasis level="moderate"><prosody pitch="+10%">
â”œâ”€â”€ "sadness" â†’ <emphasis level="reduced"><prosody pitch="-5%">
â”œâ”€â”€ "tension" â†’ <emphasis level="strong"><prosody pitch="+15%">
â””â”€â”€ Custom values â†’ logged as unsupported, no SSML applied

Inline markers in text:
â”œâ”€â”€ ... (ellipsis) â†’ <break time="500ms"/>
â”œâ”€â”€ â€” (em dash) â†’ <break time="300ms"/>
â””â”€â”€ Paragraph break â†’ <break time="1000ms"/>

```python
# src/audioformation/engines/edge_tts.py
def direction_to_ssml(text: str, direction: dict) -> str:
    """Wrap text in SSML tags based on direction config."""
```
- For XTTS: Direction field affects reference audio selection
and generation parameters, not SSML (XTTS doesn't support SSML).
Direction is engine-adaptive.

2. FXForge (Sound Effects)
```text
Modes:
â”œâ”€â”€ Procedural       # Oscillator-based synthesis
â”‚   â”œâ”€â”€ Ambient pads (drone, atmosphere)
â”‚   â”œâ”€â”€ UI sounds (click, hover, confirm)
â”‚   â”œâ”€â”€ Narrative SFX (whoosh, impact, transition)
â”‚   â””â”€â”€ Custom (frequency, filter, envelope params in JSON)
â”‚
â”œâ”€â”€ Sample-based     # Import WAV/MP3 files
â”‚   â””â”€â”€ Trim, normalize, tag, catalog
â”‚
â””â”€â”€ Hybrid           # Layer procedural + samples
```
3. ComposeEngine (Music/Composition)
```text
Tier 1: Ambient Pad Generator â† PHASE 2 (this is what audiobooks need)
â”œâ”€â”€ Drone + filtered noise + LFO modulation
â”œâ”€â”€ Mood presets: contemplative, tense, wonder, melancholy, triumph
â”œâ”€â”€ Loopable, non-fatiguing, configurable duration
â”œâ”€â”€ Pure numpy synthesis â†’ WAV output
â””â”€â”€ Good enough for 90% of audiobook background needs

Tier 2: Import + Process â† PHASE 3
â”œâ”€â”€ Import royalty-free music files (WAV/MP3)
â”œâ”€â”€ Auto-trim, fade, normalize
â”œâ”€â”€ Loop-point detection
â”œâ”€â”€ Catalog in 05_MUSIC/catalog.json
â””â”€â”€ Tag with mood/tempo/key metadata

Tier 3: Algorithmic Composition â† PHASE 4 (only if Tier 1+2 insufficient)
â”œâ”€â”€ Constrained grammar + heavy preset library
â”œâ”€â”€ Scale/key-aware generation
â”œâ”€â”€ MIDI export for external refinement
â”œâ”€â”€ Consider FishAudio-S1 or IndexTTS integration if mature by then
â””â”€â”€ NOT in v1.0 scope â€” code exists from prototypes, park it

NOTE: Pure algorithmic music without heavy presets & rules sounds
immediately recognizable as "AI slop." Ambient pads are the honest
path for audiobook production. Saving composition ambitions for v2.0.
```
4. MixBus (Mixing/Layering)
```text
Features:
â”œâ”€â”€ Multi-track timeline (voice + SFX + music)
â”œâ”€â”€ Per-track volume, pan, fade in/out
â”œâ”€â”€ Chapter assembly (stitch segments in order)
â”œâ”€â”€ Normalization (LUFS targeting for broadcast)
â”‚ â”œâ”€â”€ Measure: pyloudnorm (in-process, per-file)
â”‚ â”œâ”€â”€ Normalize: ffmpeg loudnorm filter (batch, fast)
â”‚ â””â”€â”€ Target: -16 LUFS integrated (audiobook standard)
â”œâ”€â”€ Auto-ducking (voice-triggered music attenuation)
â”‚ â”œâ”€â”€ Trigger: silero-vad v6.2 (voice activity detection)
â”‚ â”œâ”€â”€ NOT energy-based (Arabic speech has dynamic energy â€” VAD is more robust)
â”‚ â”œâ”€â”€ Look-ahead buffer: 200ms before voiced region
â”‚ â”œâ”€â”€ Gain ramp: 100ms attack, 500ms release
â”‚ â”œâ”€â”€ Attenuation: -12 dB default (configurable)
â”‚ â””â”€â”€ Output: gain-envelope applied to music track before mix
â””â”€â”€ Preview before export
```
5. ShipIt (Export)
```text
Formats:
â”œâ”€â”€ WAV (lossless, production master)
â”œâ”€â”€ MP3 (distribution, configurable bitrate via ffmpeg)
â”œâ”€â”€ FLAC (lossless compressed, archival)
â”œâ”€â”€ M4B (audiobook with chapter markers) â† PRIMARY FORMAT
â””â”€â”€ MIDI (from ComposeEngine, if used)

M4B Audiobook Pipeline (ffmpeg + mutagen):
â”œâ”€â”€ 1. Validate cover art
â”‚ Required: JPEG or PNG
â”‚ Dimensions: 1400Ã—1400 minimum, 3000Ã—3000 maximum
â”‚ Aspect ratio: must be square (1:1)
â”‚ Fail export with clear message if invalid
â”‚ (iTunes/Audible reject non-compliant covers)
â”‚
â”œâ”€â”€ 2. Apply chapter transitions
â”‚ Default: silence (gap_between_chapters_sec)
â”‚ Optional: transition sound file
â”‚ Config: "chapter_transition": "silence" | "path/to/chime.wav"
â”‚
â”œâ”€â”€ 3. Concatenate chapter WAVs â†’ single file
â”‚ ffmpeg -f concat -i chapters.txt -c copy concat.wav
â”‚
â”œâ”€â”€ 4. Encode to AAC
â”‚ ffmpeg -i concat.wav -c:a aac -b:a 128k -movflags +faststart body.m4a
â”‚
â”œâ”€â”€ 5. Write chapter metadata file (ffmetadata format)
â”‚ [CHAPTER] TIMEBASE=1/1000 START=0 END=180000 title=Chapter 1
â”‚
â”œâ”€â”€ 6. Merge metadata
â”‚ ffmpeg -i body.m4a -i metadata.txt -map_metadata 1 -c copy output.m4b
â”‚
â”œâ”€â”€ 7. Embed cover art + ID3 tags via mutagen
â”‚
â””â”€â”€ 8. Generate manifest.json with SHA256 checksums per file
```

## Project Structure
```text
PROJECTS/
â””â”€â”€ MY_NOVEL_2026/
    â”œâ”€â”€ project.json          # Single source of truth
    â”œâ”€â”€ pipeline-status.json  # Node execution state
    â”‚
    â”œâ”€â”€ 00_CONFIG/
    â”‚   â”œâ”€â”€ characters.json   # Voice profiles + personas
    â”‚   â”œâ”€â”€ engines.json      # Engine preferences + API keys
    â”‚   â””â”€â”€ hardware.json     # Auto-detected capabilities
    â”‚
    â”œâ”€â”€ 01_TEXT/
    â”‚   â”œâ”€â”€ chapters/
    â”‚   â”‚   â”œâ”€â”€ ch01.txt
    â”‚   â”‚   â”œâ”€â”€ ch02.txt
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ metadata.json     # Chapter order, language tags
    â”‚
    â”œâ”€â”€ 02_VOICES/
    â”‚   â”œâ”€â”€ references/       # Voice cloning samples
    â”‚   â”‚   â”œâ”€â”€ narrator.wav
    â”‚   â”‚   â””â”€â”€ hero.wav
    â”‚   â””â”€â”€ profiles.json     # Voice-to-character mapping
    â”‚
    â”œâ”€â”€ 03_GENERATED/
    â”‚   â”œâ”€â”€ raw/              # Direct TTS output
    â”‚   â””â”€â”€ processed/        # Post-processed (normalized)
    â”‚
    â”œâ”€â”€ 04_SFX/
    â”‚   â”œâ”€â”€ procedural/       # Generated SFX
    â”‚   â”œâ”€â”€ samples/          # Imported samples
    â”‚   â””â”€â”€ catalog.json      # SFX registry
    â”‚
    â”œâ”€â”€ 05_MUSIC/
    â”‚   â”œâ”€â”€ generated/        # Algorithmic compositions
    â”‚   â”œâ”€â”€ imported/         # Brought-in tracks
    â”‚   â””â”€â”€ midi/             # MIDI exports
    â”‚
    â”œâ”€â”€ 06_MIX/
    â”‚   â”œâ”€â”€ sessions/         # Mix configurations
    â”‚   â””â”€â”€ renders/          # Mixed output (pre-export)
    â”‚
    â””â”€â”€ 07_EXPORT/
        â”œâ”€â”€ audiobook/        # Final M4B/MP3
        â”œâ”€â”€ chapters/         # Individual chapter exports
        â””â”€â”€ manifest.json     # Export log + checksums
```
## Security & Project Hygiene

### Threat Model (Scoped)
Threats addressed:
â”œâ”€â”€ Path traversal from user input (project IDs, file paths)
â”œâ”€â”€ Injection in filenames (chapter names â†’ file system)
â”œâ”€â”€ API key exposure in version control
â””â”€â”€ Malformed project.json causing crashes

NOT in scope (v1.0):
â”œâ”€â”€ Multi-user authentication
â”œâ”€â”€ Network-facing deployment security
â””â”€â”€ DRM / content protection

### Implementation
src/audioformation/utils/security.py:
â”œâ”€â”€ sanitize_project_id(id) â†’ str # alphanumeric + underscore + hyphen only
â”œâ”€â”€ sanitize_filename(name) â†’ str # strip path separators, null bytes
â”œâ”€â”€ validate_path_within(path, root) â†’ bool # prevent traversal
â””â”€â”€ redact_api_keys(config) â†’ dict # for logging

### Auto-Generated .gitignore

Bootstrap creates `.gitignore` in every project:

```gitignore
# API keys â€” NEVER commit
00_CONFIG/engines.json

# Generated audio (large files)
03_GENERATED/**/*.wav
03_GENERATED/**/*.mp3
04_SFX/procedural/**/*.wav
05_MUSIC/generated/**/*.wav
06_MIX/renders/**/*.wav

# Exports
07_EXPORT/**/*.mp3
07_EXPORT/**/*.m4b
07_EXPORT/**/*.wav

# Keep directory structure
!**/.gitkeep
```

Port Assignments
```text
AudioFormation Dashboard:  localhost:4001
AudioFormation API:        localhost:4001
VideoFormation Dashboard:  localhost:3000
VideoFormation API:        localhost:3001
```
- No collisions. Both can run simultaneously.


## Pipeline Nodes
```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PIPELINE STATE MACHINE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚ [NEW PROJECT]                                                 â”‚
â”‚                                                               â”‚
â”‚       â–¼                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚
â”‚ â”‚0:Bootstrapâ”‚  Create folders, detect hardware                â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                                 â”‚
â”‚       â–¼                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”‚
â”‚ â”‚1:Ingest  â”‚  Import text, assign languages                   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                                  â”‚
â”‚       â–¼                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”‚
â”‚ â”‚2:Validateâ”‚ â—„â”€â”€ HARD GATE                                    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                                  â”‚
â”‚       â”‚                                                       â”‚
â”‚       â”‚ Checks:                                               â”‚
â”‚       â”‚ â€¢ Text files exist + non-empty                        â”‚
â”‚       â”‚ â€¢ Characters defined + voices assigned                â”‚
â”‚       â”‚ â€¢ Engine available (GPU/network test)                 â”‚
â”‚       â”‚ â€¢ Arabic diacritics preprocessed                      â”‚
â”‚       â”‚ â€¢ LUFS target defined                                 â”‚
â”‚       â”‚                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚ â”‚ [PASS] FAIL] â”‚ â”€â”€â–º fix & retry                              â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â”‚       â–¼                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”‚
â”‚ â”‚3:Generateâ”‚  Run TTS per chapter/character                   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                                  â”‚
â”‚       â”‚   â€¢ Chunk text into breath-groups                     â”‚
â”‚       â”‚   â€¢ Generate per-chunk with engine                    â”‚
â”‚       â”‚   â€¢ Crossfade chunks                                  â”‚
â”‚       â”‚   â€¢ Measure LUFS + true-peak per file                 â”‚
â”‚       â–¼                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”‚
â”‚ â”‚3.5:QC    â”‚ â—„â”€â”€ AUTO GATE (per chunk)                        â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  Checks per chunk:                               â”‚
â”‚       â”‚   â€¢ SNR > threshold                                   â”‚
â”‚       â”‚   â€¢ Short-time energy variance                        â”‚
â”‚       â”‚   â€¢ Pitch continuity (catch glitches)                 â”‚
â”‚       â”‚   â€¢ Duration sanity (expected Â±30%)                   â”‚
â”‚       â”‚   â€¢ Clipping detection (> -0.5 dBFS)                  â”‚
â”‚       â”‚   â€¢ LUFS within Â±3 of target                          â”‚
â”‚       â”‚                                                       â”‚
â”‚       â”‚ Results: PASS / WARN / FAIL                           â”‚
â”‚       â”‚ FAIL â†’ auto-retry (max 3)                             â”‚
â”‚       â”‚ >5% FAIL rate â†’ halt pipeline                         â”‚
â”‚       â”‚ Output: qc_report.json                                â”‚
â”‚       â”‚                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                                 â”‚
â”‚ â”‚ [PASS]    â”‚ [>5% FAIL]â”€â”€â–º review qc_report, fix & retry     â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                                 â”‚
â”‚       â–¼                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”‚
â”‚ â”‚4:Process â”‚  Normalize (ffmpeg loudnorm to target)           â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  Trim silence, consistent gaps                   â”‚
â”‚       â–¼                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”‚
â”‚ â”‚5:Compose â”‚  (Optional) Ambient pads / import music          â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                                  â”‚
â”‚       â–¼                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”‚
â”‚ â”‚6:Mix     â”‚  Layer voice + SFX + music                       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  VAD-based ducking (silero-vad)                  â”‚
â”‚       â”‚      Chapter assembly                                 â”‚
â”‚       â–¼                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”‚
â”‚ â”‚7:QC Finalâ”‚ â—„â”€â”€ HARD GATE                                    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  Checks on mixed output:                         â”‚
â”‚       â”‚   â€¢ Integrated LUFS within Â±1 of target               â”‚
â”‚       â”‚   â€¢ True-peak < -1.0 dBTP                             â”‚
â”‚       â”‚   â€¢ No silence gaps > configured max                  â”‚
â”‚       â”‚   â€¢ No clipping in final mix                          â”‚
â”‚       â”‚   â€¢ Chapter boundaries aligned                        â”‚
â”‚       â”‚                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                                 â”‚
â”‚ â”‚ [PASS]    â”‚ [FAIL]â”€â”€â–º remix & retry                         â”‚
â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                                 â”‚
â”‚       â–¼                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”‚
â”‚ â”‚8:Export  â”‚  Render final formats                            â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  MP3 + M4B + metadata + checksums                â”‚
â”‚              manifest.json with SHA256                        â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Node Summary Table

| Node | Name | Status | Description |
|---|---|---|---|
| 0â€“8 | All nodes | âœ… BUILT + E2E VERIFIED | Full pipeline tested end-to-end Feb 17, 2026 |

## Tech Stack
```text
## Tech Stack

| Layer | Technology | Why | Verified Status (Feb 2026) |
|---|---|---|---|
| Runtime | Python 3.11+ | All TTS libs are Python | âœ… Stable |
| API Server | FastAPI + Uvicorn | Async, fast, auto-docs | âœ… Stable |
| CLI | Click | Clean, composable | âœ… Stable |
| Audio I/O | pydub + ffmpeg | Universal format support | âœ… Industry standard |
| TTS: Free | edge-tts (rany2/edge-tts) | âœ… BUILT v7 - Fixed 403 DRM errors |
| TTS: Fallback | gTTS (Google TTS) | âœ… BUILT - Emergency fallback engine |
| TTS: Local | coqui-tts (idiap fork) | Voice cloning, offline, XTTS-v2 | âš ï¸ Coqui AI shutdown late 2024. Community fork by Idiap (pip install coqui-tts ~0.27.x). Pin version. Still best local cloning option. **transformers<5 (coqui-tts breaks with v5)** |
| TTS: Cloud | httpx | Generic API client | âœ… Stable |
| Synthesis | numpy + soundfile | Procedural audio generation | âœ… Stable |
| LUFS Metering | pyloudnorm + ffmpeg loudnorm | Dual approach: in-process analysis (pyloudnorm) + batch normalization (ffmpeg loudnorm filter) | âœ… pyloudnorm v0.2.0 Jan 2026. For batch: ffmpeg loudnorm faster |
| VAD (Ducking) | silero-vad v6.2 | Voice activity detection for ducking trigger | âœ… Excellent. CPU-efficient, low false positives. `pip install silero-vad` |
| Music | numpy + midiutil | Ambient pad generation + MIDI export | âœ… Stable |
| Audiobook Export | ffmpeg + mutagen | M4B with chapters, cover art, metadata | âœ… ffmpeg = canonical M4B tool. mutagen for ID3/cover. mp4v2 is legacy â€” skip it |
| Dashboard | Vanilla HTML/JS | Zero build step, portable | âœ… No dependencies |
| Packaging | PyInstaller (primary), Nuitka (benchmark later) | .exe distribution | âœ… PyInstaller safest for ML+audio stack. Nuitka faster startup if needed |
| Testing | pytest | Standard Python testing | âœ… Stable |
```

## Dependency Install (Reference)

```bash
pip install click fastapi uvicorn pydub edge-tts coqui-tts httpx mishkal
pip install numpy soundfile pyloudnorm silero-vad mutagen midiutil
pip install pytest httpx[test]
# System: ffmpeg must be on PATH
```

## Version Pinning Strategy
Pin coqui-tts and silero-vad explicitly in pyproject.toml.
These are community-maintained â€” treat as "stable but not guaranteed long-term."
All other dependencies are mature ecosystem packages with standard semver.

## CLI Design

```bash
# Project Management
audioformation new "MY_NOVEL"
audioformation list
audioformation status MY_NOVEL
audioformation hardware

# Pipeline Execution
audioformation ingest MY_NOVEL --source ./chapters/
audioformation validate MY_NOVEL
audioformation generate MY_NOVEL --engine edge
audioformation generate MY_NOVEL --engine xtts --device gpu
audioformation generate MY_NOVEL --engine xtts --device cpu
audioformation qc MY_NOVEL
audioformation qc MY_NOVEL --report
audioformation process MY_NOVEL
audioformation compose MY_NOVEL --preset contemplative
audioformation mix MY_NOVEL
audioformation qc-final MY_NOVEL
audioformation export MY_NOVEL --format mp3 --bitrate 192
audioformation export MY_NOVEL --format m4b

# Engine Management
audioformation engines list
audioformation engines test edge
audioformation engines test xtts --device gpu
audioformation engines voices edge --lang ar

# Character Management
audioformation cast list MY_NOVEL
audioformation cast add MY_NOVEL --name "Narrator" --voice ar-SA-HamedNeural --engine edge
audioformation cast clone MY_NOVEL --name "Hero" --reference ./hero.wav --engine xtts

# Quick Generation (no project needed)
audioformation quick "Hello world" --engine edge --voice en-US-GuyNeural -o hello.mp3
audioformation quick "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…" --engine edge --voice ar-SA-HamedNeural -o hello_ar.mp3
echo "Ù…Ø±Ø­Ø¨Ø§" | audioformation quick --engine edge --voice ar-SA-HamedNeural

# Preview & Compare (iteration tools)
audioformation preview MY_NOVEL ch01 --duration 30s
audioformation compare MY_NOVEL ch01 --engines edge,xtts

# Dry Run (estimation before committing)
audioformation run MY_NOVEL --all --dry-run
# Output: estimated time, chunk count, API calls, cloud cost

# Dashboard
audioformation serve

# Full Pipeline
audioformation run MY_NOVEL --all
audioformation run MY_NOVEL --from generate

### Command Details
Command	Purpose
preview	Generate first 30s (default) of a chapter with current settings. Essential for voice iteration
compare	A/B generate same text with different engines â†’ outputs to 03_GENERATED/compare/ for listening
--dry-run	Estimate time, chunks, API calls, cost. No generation. Uses current project.json to calculate
echo ... | quick	Stdin support for scripting and quick tests

## project.json Schema (Core)

```json
{
  "id": "MY_NOVEL_2026",
  "version": "1.0",
  "created": "2026-02-12T23:30:00Z",
  "languages": ["ar", "en"],

  "chapters": [
    {
      "id": "ch01",
      "title": "Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©",
      "language": "ar",
      "source": "01_TEXT/chapters/ch01.txt",
      "character": "narrator",
      "direction": {
        "energy": "quiet contemplation",
        "pace": "slow, deliberate",
        "emotion": "wonder"
      }
    }
  ],

  "characters": {
    "narrator": {
      "name": "Ø§Ù„Ø±Ø§ÙˆÙŠ",
      "engine": "edge",
      "voice": "ar-SA-HamedNeural",
      "persona": "Calm authority, philosophical depth",
      "reference_audio": null
    },
    "hero": {
      "name": "Ø§Ù„Ø¨Ø·Ù„",
      "engine": "xtts",
      "voice": null,
      "persona": "Young, determined, searching",
      "reference_audio": "02_VOICES/references/hero.wav"
    }
  },

  "generation": {
    "fallback_scope": "chapter",  // âœ… Implemented (Item 2)
    "fallback_chain": ["edge", "gtts"],
    "chunk_max_chars": 200,
    "chunk_strategy": "breath_group",
    "crossfade_ms": 120,
    "crossfade_overrides": {      // âœ… Implemented (Item 4)
      "edge": 120,
      "xtts": 80,
      "gtts": 150
    },
    "crossfade_min_ms": 50,
    "leading_silence_ms": 100,
    "max_retries_per_chunk": 3,
    "fail_threshold_percent": 5,
    "xtts_temperature": 0.7,
    "xtts_repetition_penalty": 5.0,
    "edge_tts_rate_limit_ms": 200,
    "edge_tts_concurrency": 4,
    "edge_tts_ssml": true,
    "xtts_vram_management": "empty_cache_per_chapter"
  },

  "qc": {
  "snr_method": "vad_noise_floor",
  "snr_min_db": 20,
  "max_duration_deviation_percent": 30,
  "clipping_threshold_dbfs": -0.5,
  "lufs_deviation_max": 3,
  "pitch_jump_max_semitones": 12,
  "boundary_artifact_check": true
},

  "mix": {
    "master_volume": 0.9,
    "target_lufs": -16,
    "true_peak_limit_dbtp": -1.0,
    "gap_between_chapters_sec": 2.0,
    "ducking": {
      "method": "vad",
      "vad_model": "silero-vad",
      "vad_threshold": 0.5,
      "vad_threshold_ar": 0.45,
      "look_ahead_ms": 200,
      "attack_ms": 100,
      "release_ms": 500,
      "attenuation_db": -12,
      "frequency_aware": false
    }
  },

  "export": {
  "formats": ["mp3", "m4b"],
  "mp3_bitrate": 192,
  "m4b_aac_bitrate": 128,
  "include_cover_art": true,
  "cover_art": "00_CONFIG/cover.jpg",
  "chapter_transition": "silence",
  "chapter_transition_file": null,
  "metadata": {
    "author": "",
    "narrator": "",
    "publisher": "",
    "year": 2026,
    "description": ""
  }
 }
}
```

### Chapter Schema (Multi-Speaker Support)

Chapters support both single-narrator and multi-speaker dialogue.
Format is defined now. Single-narrator is Phase 1. Multi-speaker
parsing is Phase 2. Schema supports both from day one.

#### Single-Narrator Chapter (Phase 1)

```json
{
  "id": "ch01",
  "title": "Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©",
  "language": "ar",
  "source": "01_TEXT/chapters/ch01.txt",
  "character": "narrator",
  "mode": "single",
  "direction": {
    "energy": "quiet contemplation",
    "pace": "slow, deliberate",
    "emotion": "wonder"
  }
}
```
#### Multi-Speaker Chapter 
```json
{
  "id": "ch03",
  "title": "Ø§Ù„Ù…ÙˆØ§Ø¬Ù‡Ø©",
  "language": "ar",
  "source": "01_TEXT/chapters/ch03.txt",
  "mode": "multi",
  "default_character": "narrator",
  "direction": {
    "energy": "building tension",
    "pace": "moderate, accelerating",
    "emotion": "confrontation"
  }
}
```

**Implementation Details:**
- **Per-segment character resolution**: Each `[speaker_id]` tag routes to specific character â†’ engine â†’ voice
- **Engine tracking**: Tracks all engines used per chapter for proper VRAM cleanup
- **Fallback handling**: Unknown characters fall back to chapter default engine
- **Backward compatibility**: Single mode chapters work unchanged
- **Text format**: Simple `[speaker_id]` tags on separate lines, blank lines revert to default

**Text Example:**
```text
Ù‚Ø§Ù„ Ø§Ù„Ø±Ø§ÙˆÙŠ Ø¨ØµÙˆØª Ù‡Ø§Ø¯Ø¦.

[hero] Ù„Ù† Ø£Ø³ØªØ³Ù„Ù… Ø£Ø¨Ø¯Ø§Ù‹.

[villain] Ø³Ù†Ø±Ù‰ Ø¹Ù† Ù‚Ø±Ø¨.

Ø¹Ø§Ø¯ Ø§Ù„Ø±Ø§ÙˆÙŠ ÙŠÙƒÙ…Ù„ Ø§Ù„Ù‚ØµØ©.
```

## Arabic Text Processing Strategy

Arabic is the harder case and validates the entire pipeline. Treating it
as a first-class concern, not an afterthought.

### Diacritics (ØªØ´ÙƒÙŠÙ„)

Undiacritized Arabic is ambiguous â€” the same consonant skeleton can
represent multiple words with different pronunciations. TTS quality
depends heavily on correct diacritization.

- Strategy: Detect â†’ Auto-diacritize â†’ Allow manual override
```text
Pipeline:
â”œâ”€â”€ 1. Detect diacritization level
â”‚ Count diacritical marks / total characters
â”‚ < 5% â†’ "undiacritized" â†’ auto-diacritize
â”‚ > 30% â†’ "diacritized" â†’ pass through
â”‚ 5-30% â†’ "partial" â†’ warn, offer auto-diacritize
â”‚
â”œâ”€â”€ 2. Auto-diacritize (when needed)
â”‚ Primary: Mishkal (pip install mishkal)
â”‚ â”œâ”€â”€ Lightweight, fast, pure Python
â”‚ â”œâ”€â”€ Good for MSA (Modern Standard Arabic)
â”‚ â””â”€â”€ Sufficient for most literary Arabic
â”‚ Fallback: CAMeL Tools (heavier, better disambiguation)
â”‚ â””â”€â”€ Only if Mishkal quality insufficient for project
â”‚
â”œâ”€â”€ 3. Store both versions
â”‚ 01_TEXT/chapters/ch01.txt â† original
â”‚ 01_TEXT/chapters/ch01.diacritized.txt â† processed
â”‚ Generation uses .diacritized.txt
â”‚ User can manually edit the diacritized version
â”‚
â””â”€â”€ 4. Validate gate checks:
â€¢ Diacritized file exists for each Arabic chapter
â€¢ Diacritization level > 30% in processed file
â€¢ Warn on any words that Mishkal flagged as ambiguous
```

### Mixed Arabic-English Text
- Strategy: Language-tagged segments within chunks
Detection:
â”œâ”€â”€ Unicode block analysis per word
â”‚ Arabic: U+0600â€“U+06FF, U+0750â€“U+077F, U+FB50â€“U+FDFF
â”‚ Latin: U+0041â€“U+007A, U+00C0â€“U+024F
â”‚
â”œâ”€â”€ Tag each segment: [ar] or [en]
â”‚
â””â”€â”€ Chunk splitting respects language boundaries:
â€¢ Never split mid-word
â€¢ Prefer splitting at language transition points
â€¢ Short inline English (proper nouns, 1-3 words) stays in Arabic chunk
â€¢ Longer English passages get their own chunk with English voice

For edge-tts:
â”œâ”€â”€ Arabic-primary voice handles short English inline (acceptable quality)
â””â”€â”€ Switch voice for extended English passages (>10 words)

For XTTS:
â”œâ”€â”€ Mid-sentence language switching is unreliable
â””â”€â”€ Always split at language boundary for XTTS

### Dialect-Voice Matching
```text
project.json per-character field:

"narrator": {
"dialect": "msa", â† msa | eg | sa | ae | lb | ...
"voice": "ar-SA-HamedNeural"
}

Validate gate:
â”œâ”€â”€ WARN if dialect=eg but voice=ar-SA-*
â”œâ”€â”€ WARN if dialect=sa but voice=ar-EG-*
â”œâ”€â”€ Does NOT block â€” user may intentionally cross-match
â””â”€â”€ Informational only, logged in validation report

Dialect mapping for edge-tts voices:
â”œâ”€â”€ msa â†’ ar-SA-HamedNeural (best general MSA)
â”œâ”€â”€ eg â†’ ar-EG-SalmaNeural / ar-EG-ShakirNeural
â”œâ”€â”€ ae â†’ ar-AE-FatimaNeural / ar-AE-HamdanNeural
â””â”€â”€ (extensible in engines.json)
```

### Implementation Location
src/audioformation/utils/arabic.py:
â”œâ”€â”€ detect_diacritization_level(text) â†’ float
â”œâ”€â”€ auto_diacritize(text, engine="mishkal") â†’ str
â”œâ”€â”€ detect_language_segments(text) â†’ List[Segment]
â”œâ”€â”€ split_at_language_boundaries(text, max_chars) â†’ List[Chunk]
â””â”€â”€ validate_dialect_voice_match(dialect, voice) â†’ Warning | None

### Inline Markup Format (in text files)
```text
Ù‚Ø§Ù„ Ù„Ù‡ Ø¨ØµÙˆØª Ù‡Ø§Ø¯Ø¦ ÙˆÙ‡Ùˆ ÙŠÙ†Ø¸Ø± Ø¥Ù„Ù‰ Ø§Ù„Ø£ÙÙ‚ Ø§Ù„Ø¨Ø¹ÙŠØ¯.

[hero] Ù„Ù† Ø£Ø³ØªØ³Ù„Ù… Ø£Ø¨Ø¯Ø§Ù‹. Ù…Ù‡Ù…Ø§ ÙƒØ§Ù† Ø§Ù„Ø«Ù…Ù†.

[villain] Ø³Ù†Ø±Ù‰ Ø°Ù„Ùƒ. Ø§Ù„ÙˆÙ‚Øª Ù„ÙŠØ³ ÙÙŠ ØµØ§Ù„Ø­Ùƒ.

Ø¹Ø§Ø¯ Ø§Ù„ØµÙ…Øª ÙŠÙ…Ù„Ø£ Ø§Ù„Ù…ÙƒØ§Ù†ØŒ Ø«Ù‚ÙŠÙ„Ø§Ù‹ ÙƒØºÙŠÙ…Ø© Ø±Ù…Ø§Ø¯ÙŠØ©.
```
#### Rules:
```text
Unmarked text â†’ default_character
[character_id] at line start â†’ switches speaker
Speaker persists until next tag or blank line
Blank line â†’ revert to default_character
Tags must match character IDs in project.json
âœ… BUILT: Parse tags â†’ split into speaker segments
â†’ generate each segment with assigned character's voice
â†’ stitch in order with appropriate crossfade
â†’ proper VRAM cleanup for all engines used
```
#### Parser Location (âœ… BUILT)
```text
src/audioformation/utils/text.py:
â”œâ”€â”€ parse_chapter_segments(text, mode, default_char) â†’ List[Segment]
â”‚   Segment = { character: str, text: str, index: int }
â”œâ”€â”€ chunk_segment(segment, max_chars, strategy) â†’ List[Chunk]
â””â”€â”€ validate_speaker_tags(text, known_characters) â†’ List[Warning]

src/audioformation/generate.py:
â”œâ”€â”€ _generate_chapter() â†’ Per-segment character resolution
â”œâ”€â”€ engines_used tracking â†’ VRAM management for all engines
â””â”€â”€ Fallback handling â†’ Unknown characters â†’ default engine
```
*This format is intentionally simple. No XML, no SSML in source
files. Just [speaker_id] on its own line. Easy to write,
easy to parse, easy to read in any text editor.*

### Pipeline Status Tracking (Chunk-Level Resumability)

`pipeline-status.json` tracks state at **chunk level** for Generate,
not just node level. If generation crashes at chapter 22, chunk 15,
it resumes from exactly there.

```json
{
  "project_id": "MY_NOVEL_2026",
  "nodes": {
    "bootstrap": { "status": "complete", "timestamp": "..." },
    "ingest": { "status": "complete", "timestamp": "..." },
    "validate": { "status": "complete", "timestamp": "..." },
    "generate": {
      "status": "partial",
      "engine": "xtts",
      "chapters": {
        "ch01": { "status": "complete", "chunks": 18, "duration_sec": 142.3 },
        "ch21": { "status": "complete", "chunks": 24, "duration_sec": 198.7 },
        "ch22": {
          "status": "partial",
          "chunks_done": 14,
          "chunks_total": 23,
          "last_chunk_file": "03_GENERATED/raw/ch22_014.wav",
          "error": "CUDA out of memory"
        }
      }
    },
    "qc_scan": { "status": "pending" },
    "process": { "status": "pending" },
    "compose": { "status": "skipped" },
    "mix": { "status": "pending" },
    "qc_final": { "status": "pending" },
    "export": { "status": "pending" }
  }
}
```
- Resume behavior:


Long audiobook runs (hundreds of chunks) cause PyTorch VRAM
fragmentation. Explicit management strategy:

Strategies (configurable in generation config):

"empty_cache_per_chapter" (default, recommended):
â”œâ”€â”€ Keep model loaded for entire run
â”œâ”€â”€ torch.cuda.empty_cache() between chapters
â”œâ”€â”€ Good balance of speed vs stability
â””â”€â”€ Works for most 4GB GPUs

"reload_periodic":
â”œâ”€â”€ Unload and reload model every N chapters
â”œâ”€â”€ Slower but prevents fragmentation on long runs
â”œâ”€â”€ Fallback if empty_cache isn't sufficient
â”œâ”€â”€ N configurable (default: 10)

"conservative":
â”œâ”€â”€ Unload model after every chapter
â”œâ”€â”€ Slowest but most stable
â”œâ”€â”€ For systems with exactly 4GB and heavy OS VRAM usage
â””â”€â”€ Auto-selected if available VRAM < 3.5GB

Auto-detection:
â”œâ”€â”€ On bootstrap, measure available VRAM
â”œâ”€â”€ > 6GB â†’ "empty_cache_per_chapter"
â”œâ”€â”€ 4-6GB â†’ "empty_cache_per_chapter" (warn if < 4.5GB)
â”œâ”€â”€ < 4GB â†’ "conservative" + suggest CPU fallback
â””â”€â”€ Store recommendation in 00_CONFIG/hardware.json

audioformation run MY_NOVEL --from generate checks pipeline-status.json
Skips chapters with "complete" status
Resumes partial chapters from chunks_done + 1
Re-validates completed chapters' output files exist (in case of file deletion)

#### Ducking Config

```json
"ducking": {
  "method": "vad",
  "vad_model": "silero-vad",
  "vad_threshold": 0.5,
  "vad_threshold_ar": 0.45,
  "look_ahead_ms": 200,
  "attack_ms": 100,
  "release_ms": 500,
  "attenuation_db": -12,
  "frequency_aware": false
}
```

- Per-language VAD threshold: Arabic speech has different energy
profiles (emphatic consonants, guttural sounds) than English.
Default 0.5 for English, 0.45 for Arabic. Pipeline reads chapter
language tag and selects appropriate threshold.

- Frequency-aware ducking (v1.1): Instead of reducing overall
music volume, apply a sidechain high-pass filter ducking only
200Hzâ€“4kHz (speech band). Bass/sub-bass of ambient pads continues
at near-full volume. Set "frequency_aware": true to enable.
v1.0 uses simple gain ducking. v1.1 adds the filter approach.
Schema supports both now. Not using frequency-aware ducking by default.

## Implementation Phases

### Phase 1: Foundation + First Audio Output 
Status:  - All deliverables implemented, 218/218 tests passing (at Phase 1 completion)

â”œâ”€â”€ Project scaffolding (CLI: new, list, status)
â”œâ”€â”€ project.json schema + validation (jsonschema)
â”œâ”€â”€ Folder structure creation (00_CONFIG through 07_EXPORT)
â”œâ”€â”€ Hardware detection (GPU name, VRAM, CUDA availability)
â”œâ”€â”€ Text ingestion (plain text + encoding detection)
â”œâ”€â”€ Edge TTS integration (generate per-chapter)
â”œâ”€â”€ LUFS measurement on every generated file (pyloudnorm)
â”œâ”€â”€ Basic QC scan (SNR, clipping, duration sanity)
â”œâ”€â”€ qc_report.json output
â”œâ”€â”€ MP3 export (pydub + ffmpeg)
â”œâ”€â”€ pytest setup with fixtures
â”œâ”€â”€ Test with Arabic text FIRST (harder case validates easier)
â”œâ”€â”€ gTTS fallback engine integration
â”œâ”€â”€ edge-tts v7 upgrade for DRM token fix
â””â”€â”€ Engine fallback chain (edge-tts â†’ gTTS)

### Phase 2: XTTS + Characters + Processing
Status: **Completed** 
Deliverable: Voice-cloned narration with consistent quality

â”œâ”€â”€ âœ… XTTS v2 integration (coqui-tts, Idiap fork)
â”œâ”€â”€ âœ… Aggressive chunking (breath-group strategy)
â”œâ”€â”€ âœ… Character profile system (JSON-driven)
â”œâ”€â”€ âœ… Voice cloning workflow (reference audio â†’ XTTS)
â”œâ”€â”€ âœ… Cloud API adapter (httpx, abstract interface)
â”œâ”€â”€ âœ… Crossfade stitching (Smart overrides: Edge 120ms, XTTS 80ms)
â”œâ”€â”€ âœ… Engine fallback scope (Per-chapter logic implemented)
â”œâ”€â”€ âœ… Arabic diacritics preprocessing (Mishkal integration)
â”œâ”€â”€ âœ… Multi-speaker dialogue (per-segment character resolution)
â”œâ”€â”€ âœ… Ambient pad generator (Numpy synthesis, mood presets)
â”œâ”€â”€ âœ… Batch normalization (ffmpeg loudnorm filter)
â””â”€â”€ âœ… Per-chunk retry logic on QC failure

### Phase 3: Mix + Export + Dashboard
Status: **Completed** All deliverables implemented, 371/371 tests passing 
Deliverable: Full audiobook with chapters, mixed and exported

â”œâ”€â”€ âœ… Ambient pad generator (numpy synthesis, mood presets)
â”œâ”€â”€ âœ… Music/SFX import + catalog
â”œâ”€â”€ âœ… Multi-track mixer (voice + music layers)
â”œâ”€â”€ âœ… VAD-based ducking (silero-vad trigger + gain envelope)
â”œâ”€â”€ âœ… Chapter assembly (ordered concatenation)
â”œâ”€â”€ âœ… QC Final gate (LUFS, true-peak, gaps, clipping)
â”œâ”€â”€ âœ… M4B export (ffmpeg + ffmetadata chapters)
â”œâ”€â”€ âœ… Cover art + ID3 metadata (mutagen)
â”œâ”€â”€ âœ… Manifest with SHA256 checksums
â”œâ”€â”€ âœ… FastAPI server + REST endpoints
â”œâ”€â”€ âœ… Web dashboard (vanilla HTML/JS, project browser + timeline)
â””â”€â”€ âœ… Full test suite + documentation
**Dashboard: Timeline View**
Integrated `wavesurfer.js` for mix timeline.
Single dependency, gives interactive waveform display, makes the
mix step dramatically more intuitive than abstract timeline blocks.
Dashboard tabs:
â”œâ”€â”€ Projects (list, create, status overview)
â”œâ”€â”€ Editor (project.json, text files)
â”œâ”€â”€ Timeline (wavesurfer.js waveform per track)
â”œâ”€â”€ Mix (volume sliders, ducking preview, layer toggle)
â””â”€â”€ Export (format selection, cover art preview, progress)

### Phase 4: Polish + Distribution
Status: **In Progress**

Completed:
â”œâ”€â”€ âœ… Dashboard v2 (all 6 sub-phases: 4aâ€“4f)
â”œâ”€â”€ âœ… Export view + download links
â”œâ”€â”€ âœ… QC dashboard (basic list view)
â”œâ”€â”€ âœ… Cast panel + engine/voice dropdowns
â”œâ”€â”€ âœ… Direction dropdowns (SSML-mapped)
â”œâ”€â”€ âœ… Pipeline stepper + hardware panel
â”œâ”€â”€ âœ… Mix controls (ducking params)
â”œâ”€â”€ âœ… "Run From" dropdown (resume from any step)
â”œâ”€â”€ âœ… Assets tab (SFX + Music generation)
â””â”€â”€ âœ… First M4B audiobook export verified

Remaining:
â”œâ”€â”€ Server test coverage (routes.py: 0% â†’ 60%+)
â”œâ”€â”€ Cast UI engine adaptation (hide/show per engine type)
â”œâ”€â”€ Console 404 noise suppression
â”œâ”€â”€ PyInstaller packaging (.exe)
â””â”€â”€ Loco-Tunes integration (ComposeEngine Tier 3 â€” separate app, file-system handshake)

### Handover Document Structure
```text
audioformation/
â”œâ”€â”€ README.md
â”œâ”€â”€ ARCHITECTURE.md
â”œâ”€â”€ BUILD_LOG.md
â”œâ”€â”€ CHANGELOG.md
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ src/audioformation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __main__.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ project.py
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”œâ”€â”€ validation.py
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ generate.py
â”‚   â”œâ”€â”€ mix.py
â”‚   â”‚
â”‚   â”œâ”€â”€ engines/
â”‚   â”‚   â”œâ”€â”€ base.py            # Abstract engine interface
â”‚   â”‚   â”œâ”€â”€ registry.py        # Engine discovery + fallback
â”‚   â”‚   â”œâ”€â”€ edge_tts.py        # + SSML direction mapping
â”‚   â”‚   â”œâ”€â”€ gtts_engine.py     # Emergency fallback
â”‚   â”‚   â”œâ”€â”€ xtts.py            # Voice cloning + VRAM management
â”‚   â”‚   â”œâ”€â”€ elevenlabs.py      # Cloud premium TTS
â”‚   â”‚   â””â”€â”€ cloud.py           # Generic cloud adapter
â”‚   â”‚
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ processor.py       # Normalize, trim, LUFS, batch process
â”‚   â”‚   â”œâ”€â”€ mixer.py           # Multi-track + VAD ducking
â”‚   â”‚   â”œâ”€â”€ composer.py        # Ambient pad generator (5 presets)
â”‚   â”‚   â”œâ”€â”€ sfx.py             # Procedural SFX (whoosh, impact, click, drone)
â”‚   â”‚   â””â”€â”€ synthesis.py       # Low-level oscillator/noise primitives
â”‚   â”‚
â”‚   â”œâ”€â”€ qc/
â”‚   â”‚   â”œâ”€â”€ scanner.py         # Per-chunk QC (Node 3.5)
â”‚   â”‚   â”œâ”€â”€ final.py           # Final mix QC (Node 7)
â”‚   â”‚   â””â”€â”€ report.py          # qc_report.json generation
â”‚   â”‚
â”‚   â”œâ”€â”€ export/
â”‚   â”‚   â”œâ”€â”€ mp3.py             # MP3/WAV export
â”‚   â”‚   â”œâ”€â”€ m4b.py             # M4B + ffmetadata + cover art
â”‚   â”‚   â””â”€â”€ metadata.py        # Manifest + SHA256 checksums
â”‚   â”‚
â”‚   â”œâ”€â”€ server/
â”‚   â”‚   â”œâ”€â”€ app.py             # FastAPI entry + static mounts
â”‚   â”‚   â”œâ”€â”€ routes.py          # 15 REST endpoints
â”‚   â”‚   â””â”€â”€ static/            # Dashboard HTML/JS/CSS
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ arabic.py          # Diacritics, language detection, Mishkal
â”‚       â”œâ”€â”€ text.py            # Chunking, speaker tags, splitting
â”‚       â”œâ”€â”€ hardware.py        # GPU/VRAM detection + strategy
â”‚       â””â”€â”€ security.py        # Sanitization, path validation
â”‚
â”œâ”€â”€ tests/                     # 371 tests, 26 test files
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_arabic.py
â”‚   â”œâ”€â”€ test_chunking.py
â”‚   â”œâ”€â”€ test_cli_cast.py
â”‚   â”œâ”€â”€ test_cli_compose.py
â”‚   â”œâ”€â”€ test_cli_mix.py
â”‚   â”œâ”€â”€ test_cli_preview.py
â”‚   â”œâ”€â”€ test_composer.py
â”‚   â”œâ”€â”€ test_engines.py
â”‚   â”œâ”€â”€ test_export.py
â”‚   â”œâ”€â”€ test_export_m4b.py
â”‚   â”œâ”€â”€ test_ingest.py
â”‚   â”œâ”€â”€ test_mix_unit.py
â”‚   â”œâ”€â”€ test_mixer.py
â”‚   â”œâ”€â”€ test_multispeaker.py
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â”œâ”€â”€ test_processor.py
â”‚   â”œâ”€â”€ test_project.py
â”‚   â”œâ”€â”€ test_qc.py
â”‚   â”œâ”€â”€ test_qc_final.py
â”‚   â”œâ”€â”€ test_security.py
â”‚   â”œâ”€â”€ test_server.py
â”‚   â”œâ”€â”€ test_sfx.py
â”‚   â”œâ”€â”€ test_validation.py
â”‚   â””â”€â”€ test_xtts.py
â”‚
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ project.schema.json
â”‚
â””â”€â”€ docs/
```

### Future Engine Candidates (Monitor, Not Adopted Yet)

| Engine | Promise | Status Feb 2026 | Action |
|---|---|---|---|
| FishAudio-S1 | Strong multilingual cloning + emotion | Promising, not mature | Test in Phase 4 |
| IndexTTS | XTTS successor candidate, better naturalness | Paper stage, limited adoption | Monitor |
| MeloTTS | Fast CPU inference, multilingual | Weaker voice cloning | Skip unless cloning not needed |
